{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Лабораторная работа №1 (курс \"Математические методы анализа текстов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Тема: Определение частей речи и выделение именованных сущностей.\n",
    "\n",
    "\n",
    "**Выдана**:   25 февраля 2017\n",
    "\n",
    "**Дедлайн**:   <font color='red'>9:00 утра 13 марта 2017</font>\n",
    "\n",
    "**Среда выполнения**: Jupyter Notebook (Python 2.7)\n",
    "\n",
    "#### Правила:\n",
    "\n",
    "Результат выполнения задания - отчет в формате Jupyter Notebook с кодом и выводами. В ходе выполнения задания требуется реализовать все необходимые алгоритмы, провести эксперименты и ответить на поставленные вопросы. Дополнительные выводы приветствуются. Чем меньше кода и больше комментариев - тем лучше.\n",
    "\n",
    "Все ячейки должны быть \"выполненными\", при этом результат должен воспроизвдиться при проверке (на Python 2.7). Если какой-то код не был запущен или отрабатывает с ошибками, то пункт не засчитывается. Задание, сданное после дедлайна, _не принимается_. Совсем.\n",
    "\n",
    "\n",
    "Задание выполняется самостоятельно. Вы можете обсуждать идеи, объяснять друг другу материал, но не можете обмениваться частями своего кода. Если какие-то студенты будут уличены в списывании, все они автоматически получат за эту работу 0 баллов, а также предвзято негативное отношение семинаристов в будущем. Если вы нашли в Интернете какой-то код, который собираетесь заимствовать, обязательно укажите это в задании: вполне вероятно, что вы не единственный, кто найдёт и использует эту информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Постановка задачи:\n",
    "\n",
    "В данной лабораторной работе вам предстоит:\n",
    "\n",
    "- обучить скрытую марковскую модель на размеченных данных и реализовать алгоритм Витерби для задачи POS-теггинга (определение частей речи слов в тексте)\n",
    "\n",
    "- научиться использовать ряд POS-теггеров из библиотеки NLTK и сравнить качество их работы\n",
    "\n",
    "- придумать различные признаки для CRF и использовать их в реализации CRF из пакета CRFsuite для решения задачи NER (выделение именованных сущностей в тексте)\n",
    "\n",
    "- использовать готовое решение для решения задачи NER и сравнить качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Комментарии и советы:\n",
    "\n",
    "1. Для выполнения потребуются модули Python numpy, nltk, pycrfsuite (для импорта последнего нужно установить пакет python-crfsuite).\n",
    "\n",
    "2. Все необходимые для выполнения задания данные либо приложены, либо могут быть скачаны с помощью nltk.download().\n",
    "\n",
    "3. Посмотреть параметры конструктора и других методов классов можно набрав и выполнив в ячейке с кодом '?full_method_name'.\n",
    "\n",
    "4. В коде Stanford NER tagger, возможно, присутствует ошибка. Для её устранения в файле /usr/local/lib/python2.7/site-packages/nltk/tag/api.py (или его аналоге в Windows) замените строку с номером 66 на следующую: tagged_sents = self.tag_sents([untag(sent) for sent in gold])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Определение частей речи (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Мы будем решать задачу определения частей речи (POS-теггинга) с помощью скрытой марковской модели (HMM). Формула совместной плотности наблюдаемых и скрытых переменных задается как\n",
    "\n",
    "$$ p(X, T) = p(T) p(X|T) = p(t_1)  \\prod_{i=2}^N p(t_i|t_{i-1}) \\prod_{i=1}^N p(x_i|t_i)$$\n",
    "\n",
    "В данном случае:\n",
    "\n",
    "- наблюдаемые переменные $X$ - это слова корпуса;\n",
    "\n",
    "- скрытые переменные $T$ - это POS-теги."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1.1. Обучение HMM на размеченных данных\n",
    "\n",
    "Требуется построить скрытую марковскую модель и настроить все ее параметры с помощью оценок максимального правдоподобия по размеченным данным (последовательности пар слово+тег):\n",
    "\n",
    "- Вероятности переходов между скрытыми состояниями $p(t_i | t_{i - 1})$ посчитайте на основе частот биграмм POS-тегов.\n",
    "\n",
    "- Вероятности эмиссий наблюдаемых состояний $p(x_i | t_i)$ посчитайте на основе частот \"POS-тег - слово\".\n",
    "\n",
    "- Обратите внимание на проблему разреженности счетчиков и сделаейте все вероятности сглаженными по Лапласу (add-one smoothing).\n",
    "\n",
    "- Распределение вероятностей начальных состояний $p(t_1)$ задайте равномерным.\n",
    "\n",
    "Обратите внимание, что так как мы используем размеченные данные, то у нас нет необходимости в оценивании апостериорных вероятностей на скрытые переменные с помощью алгоритма forward-backword и использовании EM-алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "        \n",
    "\n",
    "class HMM(BaseEstimator) :\n",
    "    \n",
    "    def __init__(self, sequence, labels) :\n",
    "        \n",
    "        print('Построение модели...')\n",
    "        \n",
    "        self.labels_dict = dict(zip(labels, range(len(labels))))\n",
    "        word_unic = set([word[0] for word in sequence])\n",
    "        ends_unic = set([word[0][-2:] for word in sequence])\n",
    "        self.word_dict = dict(zip(word_unic, range(len(word_unic))))\n",
    "        self.ends_dict = dict(zip(ends_unic, range(len(word_unic))))\n",
    "        self.labels = labels\n",
    "        self.label_dist = np.zeros(len(labels))\n",
    "        \n",
    "        self.start_dist = 1 / len(labels) * np.ones(len(labels))\n",
    "        self.ll_matrix = np.ones((len(labels),len(labels)))\n",
    "        self.wl_matrix = np.ones((len(word_unic), len(labels)))\n",
    "        self.ends_matrix = np.ones((len(ends_unic), len(labels)))\n",
    "        self.unknown_list = []\n",
    "        \n",
    "        print('Модель построена')\n",
    "    \n",
    "    def fit(self, sequence) :\n",
    "        \n",
    "        print('Обучение модели...')\n",
    "        \n",
    "        self.wl_matrix[self.word_dict.get(sequence[0][0])][self.labels_dict.get(sequence[0][1])] += 1\n",
    "        self.label_dist[self.labels_dict.get(sequence[0][1])] += 1\n",
    "        self.ends_matrix[self.ends_dict.get(sequence[0][0][-2:])][self.labels_dict.get(sequence[0][1])] += 1\n",
    "        for i in range(1 , len(sequence)) :\n",
    "            \n",
    "            self.ll_matrix[self.labels_dict.get(sequence[i-1][1])][self.labels_dict.get(sequence[i][1])] += 1\n",
    "            self.wl_matrix[self.word_dict.get(sequence[i][0])][self.labels_dict.get(sequence[i][1])] += 1\n",
    "            self.ends_matrix[self.ends_dict.get(sequence[i][0][-2:])][self.labels_dict.get(sequence[i][1])] += 1\n",
    "            self.label_dist[self.labels_dict.get(sequence[i][1])] += 1\n",
    "        \n",
    "        self.label_dist /= len(sequence)\n",
    "        \n",
    "        ll_sum = self.ll_matrix.sum(axis = 1)\n",
    "        wl_sum = self.wl_matrix.sum(axis = 0)\n",
    "        ends_sum = self.ends_matrix.sum(axis = 0)\n",
    "            \n",
    "        self.ll_matrix = np.array([self.ll_matrix[i, :] / ll_sum[i] for i in range(self.ll_matrix.shape[0])])\n",
    "        self.wl_matrix = np.array([self.wl_matrix[:, i] / wl_sum[i] for i in range(self.wl_matrix.shape[1])]).T\n",
    "        self.ends_matrix = np.array([self.ends_matrix[:, i] / ends_sum[i] for i in range(self.wl_matrix.shape[1])]).T\n",
    "        \n",
    "        print('Модель обучена')\n",
    "    \n",
    "    def viterbi_algorithm(self, test_token_list) :\n",
    "        \n",
    "        print('Выполняется...')\n",
    "        \n",
    "        delta = np.zeros((len(self.labels), len(test_token_list)))\n",
    "        s = np.zeros((len(self.labels), len(test_token_list) - 1))\n",
    "        unknown_count = 0\n",
    "        answer = []\n",
    "        \n",
    "        \n",
    "        delta[:, 0] = np.array([np.log(self.start_dist[i]) + \\\n",
    "                                np.log(self.wl_matrix[self.word_dict.get(test_token_list[0])][i]) for i in range(len(self.labels))])\n",
    "        for i in range(1, len(test_token_list)) :\n",
    "            d_delta = delta[:, i-1]\n",
    "            if test_token_list[i] in self.word_dict :\n",
    "                word_idx = self.word_dict.get(test_token_list[i])\n",
    "                delta[:, i] = np.array([max(d_delta + np.log(self.ll_matrix[:, k])) + \\\n",
    "                                            np.log(self.wl_matrix[word_idx][k]) for k in range(len(labels))])\n",
    "                s[:, i - 1] = np.array([np.argmax(d_delta + np.log(self.ll_matrix[:, k])) for k in range(len(labels))])\n",
    "            elif test_token_list[i][-2:] in self.ends_dict :\n",
    "                ends_idx = self.ends_dict.get(test_token_list[i][-2:])\n",
    "                delta[:, i] = np.array([max(d_delta + np.log(self.ll_matrix[:, k])) + \\\n",
    "                                            np.log(self.ends_matrix[ends_idx][k]) for k in range(len(labels))])\n",
    "                s[:, i - 1] = np.array([np.argmax(d_delta + np.log(self.ll_matrix[:, k])) for k in range(len(labels))])\n",
    "            else :\n",
    "                self.unknown_list.append(i)\n",
    "                unknown_count += 1\n",
    "        \n",
    "        last_state = np.argmax(delta[:, len(test_token_list) - 1])\n",
    "        answer.append(last_state)\n",
    "        for i in range(s.shape[1] - 1, -1 , -1) :\n",
    "            last_state = int(s[last_state, i])\n",
    "            answer.append(last_state)\n",
    "        \n",
    "        tmp_list = self.labels\n",
    "        for i in self.labels_dict :\n",
    "            tmp_list[self.labels_dict.get(i)] = i\n",
    "            \n",
    "        predict = []\n",
    "        for i in range(len(answer)) :\n",
    "            predict.append(tmp_list[answer[i]])\n",
    "        predict = predict[::-1]\n",
    "        print('Готово')\n",
    "        \n",
    "        return predict\n",
    "    \n",
    "    def get_ll_matrix(self) :\n",
    "        return self.ll_matrix\n",
    "    \n",
    "    def get_wl_matrix(self) :\n",
    "        return self.wl_matrix\n",
    "    \n",
    "    def get_label_dist(self) :\n",
    "        return self.label_dist\n",
    "    \n",
    "    def get_word_dict(self) :\n",
    "        return self.word_dict\n",
    "    \n",
    "    def get_ends_matrix(self) :\n",
    "        return self.ends_matrix\n",
    "    def get_unknown_list(self) :\n",
    "        return self.unknown_list\n",
    "    def get_labels_dict(self):\n",
    "        return self.labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузите brown корпус с универсальной системой тегирования. Для этого вам понадобятся ресурсы brown и universal_tagset из nltk.download().  В этой системе содержатся следующие теги:\n",
    "\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition\t(on, of, at, ...)\n",
    "- ADV - adverb\t(really, already, still, ...)\n",
    "- CONJ\t- conjunction\t(and, or, but, ...)\n",
    "- DET - determiner, article\t(the, a, some, ...)\n",
    "- NOUN\t- noun\t(year, home, costs, ...)\n",
    "- NUM - numeral\t(twenty-four, fourth, 1991, ...)\n",
    "- PRT -\tparticle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- .\t- punctuation marks\t(. , ;)\n",
    "- X\t- other\t(ersatz, esprit, dunno, ...)\n",
    "\n",
    "Обратите внимание, что тегсеты в корпусах текстов и в различных теггерах могут быть разными. Проверять это можно, глядя на сами теги, а симптом - подозрительно низкое качество теггирования. В таких случаях рекомендуется всё приводить сперва к универсальному тегсету, а потом уже мерять качество. Полезной может оказаться эта ссылка http://www.nltk.org/_modules/nltk/tag/mapping.html\n",
    "\n",
    "Проанализируйте данные, с которыми Вы работаете. В частности, ответьте на вопросы:\n",
    "- Каков общий объем датасета, формат?\n",
    "- Приведены ли слова к нижнему регистру? Чем  это нам может в дальнейшем помешать?\n",
    "- Как распределены слова в корпусе?  Как распределены теги в корпусе? Подсчитайте частоты и отобразите любым удобным для Вас способом. Проинтерпретируйте полученные результаты.\n",
    "\n",
    "Задем сделайте случайное разбиение выборки на обучение и контроль в отношении 9:1 и обучите скрытую марковскую модель из предыдущего пункта. Если впоследствии обучение моделей будет занимать слишком много времени, работайте с подвыборкой, например, только текстами определенных категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(text, ratio = 0.9) :\n",
    "    \n",
    "    random.shuffle(text)\n",
    "    end_train = int(0.9 * len(text))\n",
    "    return text[: end_train], text[end_train : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk import corpus\n",
    "brown_tagged_set = corpus.brown.tagged_sents(tagset=\"universal\")\n",
    "train, test = train_test_split(list(brown_tagged_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "listmerge = lambda t : [el for lst in t for el in lst]\n",
    "train, test = listmerge(train), listmerge(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объем датасета =  1161192 слов\n"
     ]
    }
   ],
   "source": [
    "print(\"Объем датасета = \", len(train) + len(test), \"слов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = [(t[0].lower(), t[1]) for t in train]\n",
    "test = [(t[0].lower(), t[1]) for t in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Слова в корпусе не были приведены к нижнему регистру, что может сильно увеличить размер словаря и снизить качество разметки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = ['ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRT', 'PRON', 'VERB', '.', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Построение модели...\n",
      "Модель построена\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение модели...\n",
      "Модель обучена\n",
      "Время обучения  5.350347995758057  секунд\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "hmm.fit(train)\n",
    "print(\"Время обучения \", time.time() - t, \" секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "d_w = {}\n",
    "d_l = {}\n",
    "for w in train :\n",
    "    if w[0] in d_w :\n",
    "        d_w[str(w[0])] = d_w[str(w[0])] + 1\n",
    "    else :\n",
    "        d_w[str(w[0])] = 1\n",
    "    if w[1] in d_l :\n",
    "        d_l[str(w[1])] = d_l[str(w[1])] + 1\n",
    "    else :\n",
    "        d_l[str(w[1])] = 1\n",
    "w_sorted = sorted(d_w.items(), key=lambda t: t[1], reverse=True)\n",
    "w_sorted = w_sorted[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Частоты по словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd35fa4d828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.barplot([i[0] for i in w_sorted[:20]], [i[1] for i in w_sorted[:20]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "График частот слов согласуется с законом Ципфа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Частоты по частям речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFXCAYAAAC7nNf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEOoAABiCUAcAwBD/HwdCCnD2TsaaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd365ac6320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l_sorted = sorted(d_l.items(), key=lambda t: t[1], reverse=True)\n",
    "seaborn.barplot([i[0]for i in l_sorted], [i[1] for i in l_sorted])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Как и ожидалось наиболее часто встречающимися оказались существительные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_list = [t[0].lower() for t in test]\n",
    "test_tags = [t[1] for t in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполняется...\n",
      "Готово\n",
      "Время предсказания  30.09011220932007  секунд\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "predict = hmm.viterbi_algorithm(test_list)\n",
    "print(\"Время предсказания \", time.time() - t, \" секунд\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1.2 Алгоритм Витерби для применения модели\n",
    "\n",
    "Чтобы использовать обученную модель для определения частей речи на новых данных, необходимо реализовать алгоритм Витерби. Это алгоритм динамиеского программирования, с помощью которого мы будем находить наиболее вероятную последовательность скрытых состояний модели для фиксированной последовательности слов:\n",
    "\n",
    "$$ \\hat{T} = \\arg \\max_{T} p(T|X) = \\arg \\max_{T} p(X, T) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Определим функцию, определяющую максимальную вероятность последовательности, заканчивающейся на $i$-ой позиции в состоянии $k$:\n",
    "\n",
    "$$\\delta(k, i) = \\max_{t_1, \\dots t_{i-1}} p(x_1, \\dots x_i, t_1, \\dots t_i=k)$$\n",
    "\n",
    "Тогда $\\max_{k} \\delta(k, N)$ - максимальная вероятность всей последовательности. А состояния, на которых эта вероятность достигается - ответ задачи.\n",
    "\n",
    "Алгоритм Витерби заключается в последовательном пересчете функции $\\delta(k, i)$ по формуле:\n",
    "\n",
    "$$\\delta(k, i) = \\max_{m} \\delta(m, i-1) p(t_i = k|t_{i-1} = m) p(x_i|t_i=k) $$\n",
    "\n",
    "Аналогично пересчитывается функция, определяющая, на каком состоянии этот максимум достигается:\n",
    "\n",
    "$$s(k, i) = \\arg \\max_{m} \\delta(m, i-1) p(t_i = k|t_{i-1} = m) p(x_i|t_i=k) $$\n",
    "\n",
    "\n",
    "На практике это означает заполнение двумерных массивов размерности: (длина последовательности) $\\times$ (количество возможных состояний). Когда массивы заполнены, $\\arg \\max_{k} \\delta(k, N)$ говорит о последнем состоянии. Начиная с него можно восстановить все состояния по массиву $s$. \n",
    "\n",
    "Осталось уточнить, как стартовать последовательный пересчет (чем заполнить первый столбец массива вероятностей):\n",
    "\n",
    "$$\\delta(k, 1) = p(k) p(x_1|t_1=k)$$\n",
    "\n",
    "В реализации рекомендуется перейти к логарифмам, т.к. произведение большого числа маленьких вероятностей может приводить к вычислительным ошибкам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Проверьте работу реализованного алгоритма на следующих модельных примерах, проинтерпретируйте результат.\n",
    "\n",
    "- 'he can stay'\n",
    "- 'a milk can'\n",
    "- 'i saw a dog'\n",
    "- 'an old saw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполняется...\n",
      "Готово\n",
      "Выполняется...\n",
      "Готово\n",
      "Выполняется...\n",
      "Готово\n",
      "Выполняется...\n",
      "Готово\n"
     ]
    }
   ],
   "source": [
    "predict1 = hmm.viterbi_algorithm(['he', 'can', 'stay'])\n",
    "predict2 = hmm.viterbi_algorithm(['a', 'milk', 'can'])\n",
    "predict3 = hmm.viterbi_algorithm(['i', 'saw', 'a', 'dog'])\n",
    "predict4 = hmm.viterbi_algorithm(['an', 'old', 'saw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRON', 'VERB', 'VERB']\n",
      "['DET', 'NOUN', 'VERB']\n",
      "['PRON', 'VERB', 'DET', 'NOUN']\n",
      "['DET', 'ADJ', 'VERB']\n"
     ]
    }
   ],
   "source": [
    "print(predict1)\n",
    "print(predict2)\n",
    "print(predict3)\n",
    "print(predict4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Неправильно определилась часть слова 'saw' в 4 примере. Возможно не хватило статистики на обучении, но выглядит странно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Примените модель к отложенной выборке Брауновского корпуса и подсчитайте точность определения тегов (accuracy). Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM model accuracy =  0.944401564492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"HMM model accuracy = \", accuracy_score(test_tags, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "На отложенной выборке алгоритм показывает хорошее качество, думаю тут помогла обработка незнакомых слов (а не просто объявление их \"unknown\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1.3. Готовые POS-теггеры из NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В прошлом пункте Вы реализовали свой POS-тегер на основе скрытой марковской модели. Теперь сравните его работу с готовыми средставми, доступными в библиотеке NLTK: http://www.nltk.org/api/nltk.tag.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Примерный набор кандидатов для сравнения:\n",
    "- Простейший теггер, который всем словам ставит в соответствие одну и ту же метку\n",
    "- Основанный на правилах RegexpTagger (правила можно поискать в Интернете или придумать самим)\n",
    "- N-граммные теггеры (разберитесь и поэкспериментируйте с параметром backoff)\n",
    "- Теггеры на основе графических моделей (можно взять только Stanford): \n",
    "    - HiddenMarkovModelTagger\n",
    "    - CRFTagger\n",
    "    - StanfordPOSTagger (потребуется .jar файл теггера и обученная модель (легко находятся в Интернете), чтобы подать на вход конструктору класса)\n",
    "- BrillTagger, основанный на трансформациях\n",
    "\n",
    "Если работа с какими-то модулями приводит к техническим проблемам, которые Вы не можете решить, это не страшно, модуль можно пропустить. Однако навык быстрого освоения документации / поиска моделей в гугле полезен.  Чем более полным и корректным будет сравнение, тем лучше.\n",
    "\n",
    "При проведении экспериментов обращайте внимание на следующие моменты (и отразите их в отчете):\n",
    "- Какой подход лежит в основе теггера\n",
    "- На каких данных он обучен (если Вы скачали готовую модель)\n",
    "- Сколько времени занимает обучение на brown корпусе (если обучаете сами)\n",
    "- Какая точность получается на контролькой выборке (метод evaluate())\n",
    "\n",
    "Сформируйте рекоммендиции о том, какую технологию Вы бы использовали, если встретитесь с задачей определения частей речи в будущем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import RegexpTagger\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger\n",
    "from nltk.tag import TrigramTagger\n",
    "from nltk.tag import  HiddenMarkovModelTagger\n",
    "from nltk.tag import CRFTagger\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tag import BrillTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DefaultTagger время обучения 0.13225936889648438\n",
      "DefaultTagger accuracy =  0.23733620099\n"
     ]
    }
   ],
   "source": [
    "default_tagger = DefaultTagger('NOUN')\n",
    "t = time.time()\n",
    "default_predict = list(default_tagger.tag(test_list))\n",
    "print(\"DefaultTagger время обучения\", time.time() - t)\n",
    "print(\"DefaultTagger accuracy = \",accuracy_score(test_tags, [dp[1] for dp in default_predict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Default Tagger просто проставляет всем словам в выборке одну метку. Это самый простой тэггер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegexpTagger время обучения 5.140694618225098\n",
      "RegexpTagger accuracy =  0.644450996887\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regexp_tagger = RegexpTagger(\n",
    "    [(r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),   \n",
    "    (r'\\W+?$', '.'),\n",
    "    (r'(The|the|A|a|An|an|some|Some)$', 'DET'),   \n",
    "    (r'(one|two|tree|four|five|six|seven|eight|nine|ten|eleven|twelve)$', 'NUM'),\n",
    "    (r'(on|in|at|near|over|under|between|among|behind|across|through|to|towards|from|into|during|before|after|between)$', 'ADP'),\n",
    "    (r'(also|and|as|because|but|however|if|once|or|still|so|than|that|)$', 'CONJ'),\n",
    "    (r'(therefore|although|thus|what|while|yet|for|with|without)$', 'CONJ'),\n",
    "    (r'(i|you|he|she|it|we|they|me|him|her|it|us|them|other|another)$', 'PRON'),\n",
    "    (r'.*one$', 'NUM'),\n",
    "    (r'.*two$', 'NUM'),\n",
    "    (r'.*three$', 'NUM'),\n",
    "    (r'.*four$', 'NUM'),\n",
    "    (r'.*five$', 'NUM'),\n",
    "    (r'.*six$', 'NUM'),\n",
    "    (r'.*seven$', 'NUM'),\n",
    "    (r'.*eight$', 'NUM'),\n",
    "    (r'.*nine$', 'NUM'),\n",
    "    (r'.*th$', 'NUM'),\n",
    "    (r'.*able$', 'ADJ'),\n",
    "    (r'.*ful$', 'ADJ'),\n",
    "    (r'.*less$', 'ADJ'),\n",
    "    (r'.*ible$', 'ADJ'),\n",
    "    (r'.*ic$', 'ADJ'),\n",
    "    (r'.*ical$', 'ADJ'),\n",
    "    (r'.*ous$', 'ADJ'),\n",
    "    (r'.*ate$', 'ADJ'),\n",
    "    (r'.*ish$', 'ADJ'),\n",
    "    (r'.*ive$', 'ADJ'),\n",
    "    (r'.*ness$', 'NOUN'),                \n",
    "    (r'.*ly$', 'ADV'),\n",
    "    (r'.*ically$', 'ADV'),\n",
    "    (r'.*s$', 'NOUN'),                 \n",
    "    (r'.*ing$', 'VERB'),               \n",
    "    (r'.*ed$', 'VERB'),\n",
    "    (r'.*en$', 'VERB'),\n",
    "    (r'.*ize$', 'VERB'),\n",
    "    (r'.*fy$', 'VERB'),\n",
    "    (r'.*', 'NOUN')                     \n",
    " ])\n",
    "t = time.time()\n",
    "regexp_predict = list(regexp_tagger.tag(test_list))\n",
    "print(\"RegexpTagger время обучения\", time.time() - t)\n",
    "print(\"RegexpTagger accuracy = \",accuracy_score(test_tags, [rp[1] for rp in regexp_predict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "RegexpTagger уже более проодвинутый тэггер. Его работа построена на перечне правил, с помощью которых он размечает слова. Работает довольно быстро, но качество плохое. Думаю, что если напридумывать еще кучу правил, можно добиться отностильно неплохого качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnigrammTagger время обучения 0.6842460632324219\n",
      "UnigrammTagger accuracy =  0.8455098176019137\n"
     ]
    }
   ],
   "source": [
    "brown_tagged_sents = corpus.brown.tagged_sents(categories='news', tagset = 'universal')\n",
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "t = time.time()\n",
    "unigram_tagger = UnigramTagger(train_sents)\n",
    "print(\"UnigrammTagger время обучения\", time.time() - t)\n",
    "print(\"UnigrammTagger accuracy = \",unigram_tagger.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Униграммный тэггер ставит в соответствие слову ниболее вероятный тэг, который определяется по обучающему корпусу. \n",
    "Обучение n-gramm тэггеров проводилось на brown корпусе, катеория \"news\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigrammTagger время обучения 1.2607378959655762\n",
      "BigrammTagger accuracy =  0.8497956742748929\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "bigram_tagger = BigramTagger(train_sents, backoff = unigram_tagger)\n",
    "print(\"BigrammTagger время обучения\", time.time() - t)\n",
    "print(\"BigrammTagger accuracy = \",bigram_tagger.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Биграммный тэггер в качестве контекста использует не только сам токен, но и тэг предыдущего слова и проставляет наиболее вероятный тэг в соответствии с контекстом текущего слова. Если корпус небольшой, то тэггеру может не хватить статистики на пару (слово, предущий тэг) и качество будет неудовлетворительным. Выходом может быть композиция тэггеров. Я применил композицию биграм-тэггера и униграм-тэггера. Параметр backoff определяет алгоритм, который будет применен для разметки в случае, если не справился текущий. Качество такого тэггера заметно лучше по сравнению с тэгерром без параметра backoff и немного лучше по сравнению с униграммным тэггером. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrigrammTagger время обучения =  1.6026456356048584\n",
      "TrigrammTagger accuracy =  0.8479019236519486\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "trigram_tagger = TrigramTagger(train_sents, backoff = bigram_tagger)\n",
    "print(\"TrigrammTagger время обучения = \",time.time() - t)\n",
    "print(\"TrigrammTagger accuracy = \",trigram_tagger.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Здесь в контекст добавился еще тэг предпредыдущего слова. Качество практически не изменилось. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "os.environ['CLASSPATH'] = os.path.join(\n",
    "   os.path.curdir, 'stanford-postagger-2015-04-20'\n",
    ")\n",
    "os.environ['STANFORD_MODELS'] = os.path.join(\n",
    "    os.path.curdir, 'stanford-postagger-2015-04-20', 'models'\n",
    ")\n",
    "stanford_tagger = StanfordPOSTagger('english-bidirectional-distsim.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StanfordPOSTagger время =  9.85373854637146\n"
     ]
    }
   ],
   "source": [
    "import nltk.tag.mapping\n",
    "import time\n",
    "ts = [el[0] for lst in test_sents for el in lst]\n",
    "t = time.time()\n",
    "ts_tagging = stanford_tagger.tag(ts)\n",
    "print(\"StanfordPOSTagger время = \", time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ts_tagging = [nltk.tag.mapping.map_tag('en-ptb', 'universal', t[1]) for t in ts_tagging]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StanfordPOSTagger accuracy =  0.928934516097\n"
     ]
    }
   ],
   "source": [
    "print(\"StanfordPOSTagger accuracy = \", accuracy_score(ts_tagging,[el[1] for lst in test_sents for el in lst]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В основе Stanford тэггера модель максималльной энтропиии. Обучен на brown корпусе, катеория \"news\". Качество высокое, работает быстро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag import BrillTaggerTrainer\n",
    "\n",
    "trainer = BrillTaggerTrainer(unigram_tagger, nltk.tag.brill.brill24(), 3, ruleformat=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBL train (fast) (seqs: 4160; tokens: 90521; tpls: 24; min score: 3; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 29930 useful rules.\n",
      "\n",
      "           B      |\n",
      "   S   F   r   O  |        Score = Fixed - Broken\n",
      "   c   i   o   t  |  R     Fixed = num tags changed incorrect -> correct\n",
      "   o   x   k   h  |  u     Broken = num tags changed correct -> incorrect\n",
      "   r   e   e   e  |  l     Other = num tags changed incorrect -> incorrect\n",
      "   e   d   n   r  |  e\n",
      "------------------+-------------------------------------------------------\n",
      " 274 391 117   3  | PRT->ADP if Pos:DET@[1]\n",
      "  61  88  27   1  | PRT->ADP if Pos:NOUN@[1] & Pos:NOUN@[2]\n",
      "  51  62  11   0  | NOUN->VERB if Pos:PRT@[-1] & Pos:DET@[1]\n",
      "  35  56  21   1  | PRT->ADP if Pos:NUM@[1]\n",
      "  38  42   4   0  | ADP->PRT if Word:up@[0]\n",
      "  35  65  30   1  | PRT->ADP if Pos:NOUN@[-1] & Pos:NOUN@[1]\n",
      "  36  36   0   0  | ADP->PRT if Word:all@[0]\n",
      "  34  52  18   0  | PRT->ADP if Pos:ADJ@[1] & Pos:NOUN@[2]\n",
      "  26  51  25   0  | VERB->NOUN if Pos:DET@[-1] & Pos:ADP@[1]\n",
      "  25  47  22   0  | ADP->ADV if Word:as@[2]\n",
      "  23  23   0   0  | NOUN->VERB if Word:would@[-1]\n",
      "  21  21   0   0  | ADP->PRT if Word:out@[0]\n",
      "  20  20   0   0  | NOUN->VERB if Word:will@[-1]\n",
      "  18  38  20   4  | ADP->PRON if Pos:VERB@[1] & Pos:VERB@[2]\n",
      "  16  21   5   1  | VERB->NOUN if Pos:ADJ@[-1] & Pos:.@[1]\n",
      "  15  39  24   0  | PRT->ADP if Pos:NOUN@[1] & Pos:.@[2]\n",
      "  18  18   0   0  | ADP->PRT if Word:all@[0]\n",
      "  13  13   0   0  | ADJ->PRT if Word:such@[0] & Word:a@[1] & Pos:DET@[1]\n",
      "  11  25  14   0  | NOUN->VERB if Pos:PRON@[-1]\n",
      "  11  12   1   0  | ADV->ADJ if Word:most@[0] & Word:of@[1] & Pos:ADP@[1]\n",
      "  10  16   6   3  | PRT->ADP if Pos:PRON@[1]\n",
      "  10  10   0   0  | ADV->ADP if Word:so@[0] & Word:that@[1] & Pos:ADP@[1]\n",
      "   9  36  27   0  | VERB->NOUN if Pos:ADJ@[-1] & Pos:ADP@[1]\n",
      "   9  12   3   0  | NOUN->VERB if Word:not@[-1]\n",
      "   9   9   0   0  | ADV->ADP if Word:in@[0]\n",
      "   9   9   0   0  | ADV->ADP if Word:around@[0] & Word:the@[1] & Pos:DET@[1]\n",
      "   9  22  13   0  | PRT->ADP if Word:out@[0] & Word:of@[1] & Pos:ADP@[1]\n",
      "   8   8   0   0  | ADP->PRT if Word:All@[0,1]\n",
      "   8   8   0   0  | ADJ->ADV if Word:only@[0] & Word:not@[-1] & Pos:ADV@[-1]\n",
      "   7   8   1   0  | ADJ->VERB if Pos:PRT@[-1] & Pos:DET@[1]\n",
      "   7  11   4   0  | NOUN->VERB if Pos:PRT@[1] & Pos:DET@[2]\n",
      "   7   7   0   4  | ADP->PRT if Word:half@[0,1]\n",
      "   7   7   0   0  | ADP->DET if Word:that@[0] & Word:of@[-1] & Pos:ADP@[-1]\n",
      "   7   8   1   0  | ADP->DET if Word:that@[0] & Word:of@[1] & Pos:ADP@[1]\n",
      "   7   7   0   0  | ADP->VERB if Word:like@[0] & Word:to@[1] & Pos:PRT@[1]\n",
      "   6   6   0   0  | ADJ->VERB if Word:will@[-1]\n",
      "   6   6   0   0  | NOUN->VERB if Word:can@[-1]\n",
      "   6   6   0   0  | PRON->ADP if Word:being@[1]\n",
      "   6   6   0   0  | ADP->PRT if Word:up@[0]\n",
      "   6   9   3   0  | ADJ->ADV if Word:little@[0] & Word:a@[-1] & Pos:DET@[-1]\n",
      "   6   8   2   2  | ADV->ADJ if Pos:DET@[-1] & Pos:NOUN@[1]\n",
      "   6   7   1   0  | PRT->ADP if Word:to@[0] & Word:came@[-1] & Pos:VERB@[-1]\n",
      "   6  10   4   0  | ADP->ADV if Word:because@[0] & Word:of@[1] & Pos:ADP@[1]\n",
      "   6   6   0   0  | ADP->DET if Word:that@[0] & Word:time@[1] & Pos:NOUN@[1]\n",
      "   5   5   0   1  | ADP->ADJ if Word:the@[-1]\n",
      "   5   5   0   0  | ADP->NOUN if Word:a@[-1]\n",
      "   5   5   0   0  | NUM->NOUN if Word:no@[-1]\n",
      "   5   5   0   0  | DET->NOUN if Word:&@[1]\n",
      "   5   5   0   0  | ADV->ADP if Word:of@[0]\n",
      "   5   5   0   0  | ADP->ADV if Word:about@[0] & Word:for@[-1] & Pos:ADP@[-1]\n",
      "   5   7   2   0  | ADV->ADP if Word:so@[0] & Word:,@[-1] & Pos:.@[-1]\n",
      "   5   6   1   0  | ADJ->ADV if Word:long@[0] & Word:as@[1] & Pos:ADP@[1]\n",
      "   5   5   0   0  | ADJ->NOUN if Word:top@[0] & Word:of@[1] & Pos:ADP@[1]\n",
      "   5   6   1   0  | ADJ->NOUN if Word:worth@[0] & Word:of@[1] & Pos:ADP@[1]\n",
      "   5   5   0   5  | ADP->DET if Word:that@[0] & Word:is@[1] & Pos:VERB@[1]\n",
      "   5  12   7   0  | ADJ->ADV if Pos:ADJ@[1] & Pos:ADP@[2]\n",
      "   5   5   0   0  | ADP->PRT if Word:on@[0] & Word:to@[1] & Pos:PRT@[1]\n",
      "   4   8   4   3  | ADJ->NOUN if Pos:NOUN@[-1] & Pos:CONJ@[1]\n",
      "   4   5   1   0  | ADP->DET if Pos:ADP@[-1] & Pos:.@[1]\n",
      "   4   5   1   0  | NOUN->VERB if Pos:PRON@[1] & Pos:ADP@[2]\n",
      "   4   4   0   1  | ADJ->ADV if Word:can@[-1]\n",
      "   5   5   0   0  | NOUN->VERB if Word:only@[-1] & Pos:ADV@[-1]\n",
      "   4   4   0   2  | ADP->PRT if Word:bring@[-1]\n",
      "   5   6   1   0  | PRT->ADV if Word:about@[0]\n",
      "   4   5   1   0  | ADP->PRT if Word:took@[-1]\n",
      "   4   5   1   1  | ADJ->PRT if Word:an@[1]\n",
      "   4   4   0   0  | ADP->PRON if Word:are@[1]\n",
      "   4   4   0   0  | PRT->ADP if Word:school@[1]\n",
      "   4   4   0   0  | NOUN->VERB if Word:failed@[-2]\n",
      "   4   4   0   0  | ADP->ADV if Word:There@[-1,0]\n",
      "   4   4   0   1  | ADP->ADV if Word:there@[0]\n",
      "   4   4   0   0  | PRON->ADP if Word:in@[0]\n",
      "   4   4   0   0  | ADJ->ADV if Word:more@[0] & Word:a@[-1] & Pos:DET@[-1]\n",
      "   4   7   3   0  | ADJ->NOUN if Word:West@[0] & Word:the@[-1] & Pos:DET@[-1]\n",
      "   4   4   0   0  | ADP->PRON if Word:that@[0] & Word:one@[-1] & Pos:NUM@[-1]\n",
      "   4   4   0   0  | ADP->PRT if Word:in@[0] & Word:come@[-1] & Pos:VERB@[-1]\n",
      "   4   4   0   0  | ADP->PRT if Word:over@[0] & Word:take@[-1] & Pos:VERB@[-1]\n",
      "   4   4   0   0  | ADV->NOUN if Word:back@[0] & Word:the@[-1] & Pos:DET@[-1]\n",
      "   4   4   0   0  | NOUN->VERB if Word:run@[0] & Word:to@[-1] & Pos:PRT@[-1]\n",
      "   4   5   1   0  | PRT->ADP if Word:to@[0] & Word:up@[-1] & Pos:PRT@[-1]\n",
      "   4   4   0   0  | VERB->NOUN if Word:turn@[0] & Word:in@[-1] & Pos:ADP@[-1]\n",
      "   4   4   0   0  | ADJ->ADV if Word:early@[0] & Word:in@[1] & Pos:ADP@[1]\n",
      "   4   4   0   0  | ADP->PRT if Word:in@[0] & Word:on@[1] & Pos:ADP@[1]\n",
      "   4   4   0   0  | DET->PRON if Word:her@[0] & Word:.@[1] & Pos:.@[1]\n",
      "   4   4   0   0  | NOUN->VERB if Word:return@[0] & Word:to@[1] & Pos:ADP@[1]\n",
      "   3   3   0   0  | ADJ->NOUN if Pos:DET@[-1] & Pos:DET@[1]\n",
      "   3   4   1   1  | PRT->ADP if Pos:ADJ@[-1] & Pos:ADJ@[1]\n",
      "   3   4   1   0  | NOUN->VERB if Pos:PRON@[-2] & Pos:ADV@[-1]\n",
      "   3   3   0   0  | PRT->ADV if Pos:ADV@[-2] & Pos:CONJ@[-1]\n",
      "   3   3   0   0  | PRT->ADP if Pos:ADJ@[1] & Pos:ADJ@[2]\n",
      "   3   3   0   0  | ADJ->ADV if Word:once@[-1]\n",
      "   3   3   0   0  | ADJ->NOUN if Word:Chicago@[-1]\n",
      "   3   3   0   0  | ADJ->NOUN if Word:Middle@[-1]\n",
      "   3   3   0   0  | ADP->PRT if Word:drove@[-1]\n",
      "   3   3   0   0  | NOUN->VERB if Word:could@[-1]\n",
      "   3   3   0   0  | PRT->ADP if Word:returned@[-1]\n",
      "   3   3   0   0  | PRT->ADV if Word:from@[-1]\n",
      "   3   3   0   0  | ADJ->NOUN if Word:Electric@[1]\n",
      "   3   3   0   2  | ADJ->NOUN if Word:said@[1]\n",
      "   3   3   0   0  | PRT->ADP if Word:left@[1]\n",
      "   3   3   0   0  | VERB->NOUN if Word:call@[-2]\n",
      "   3   3   0   0  | PRT->ADP if Word:who@[2]\n",
      "   3   3   0   0  | NOUN->VERB if Pos:PRT@[-1] & Pos:PRON@[1]\n",
      "   3   5   2   0  | NOUN->VERB if Pos:ADJ@[-2] & Pos:PRT@[-1]\n",
      "   3   3   0   0  | NOUN->VERB if Word:didn't@[-2,-1]\n",
      "   3   3   0   0  | ADV->ADJ if Word:standard@[1,2]\n",
      "   3   3   0   0  | ADP->PRT if Word:that's@[-1,0]\n",
      "   3   3   0   0  | ADP->PRT if Word:you're@[-1,0]\n",
      "   3   3   0   0  | ADP->PRT if Word:It's@[0,1]\n",
      "   3   3   0   0  | ADP->PRT if Word:it's@[0]\n",
      "   3   3   0   0  | NOUN->VERB if Word:are@[0]\n",
      "   3   3   0   0  | NOUN->VERB if Word:said@[0]\n",
      "   3   3   0   0  | PRON->ADP if Word:of@[0]\n",
      "   3   3   0   0  | VERB->NOUN if Word:today@[0]\n",
      "   3   5   2   0  | ADJ->ADV if Word:more@[0] & Word:the@[-1] & Pos:DET@[-1]\n",
      "   3   3   0   0  | ADJ->ADV if Word:only@[0] & Word:was@[-1] & Pos:VERB@[-1]\n",
      "   3   3   0   0  | ADJ->NOUN if Word:individual@[0] & Word:an@[-1] &\n",
      "                  |   Pos:DET@[-1]\n",
      "   3   3   0   0  | ADP->ADV if Word:along@[0] & Word:get@[-1] & Pos:VERB@[-1]\n",
      "   3   3   0   0  | ADP->ADV if Word:upon@[0] & Word:called@[-1] &\n",
      "                  |   Pos:VERB@[-1]\n",
      "   3   3   0   0  | ADP->DET if Word:that@[0] & Word:on@[-1] & Pos:ADP@[-1]\n",
      "   3   3   0   0  | ADP->PRT if Word:down@[0] & Word:,@[-1] & Pos:.@[-1]\n",
      "   3   3   0   0  | PRT->ADP if Word:to@[0] & Word:back@[-1] & Pos:ADV@[-1]\n",
      "   3   3   0   0  | VERB->ADJ if Word:left@[0] & Word:his@[-1] & Pos:DET@[-1]\n",
      "   3   3   0   1  | VERB->ADJ if Word:left@[0] & Word:the@[-1] & Pos:DET@[-1]\n",
      "   3   3   0   0  | VERB->NOUN if Word:move@[0] & Word:the@[-1] & Pos:DET@[-1]\n",
      "   3   3   0   0  | ADJ->ADV if Word:deep@[0] & Word:into@[1] & Pos:ADP@[1]\n",
      "   3   4   1   0  | ADJ->ADV if Word:enough@[0] & Word:.@[1] & Pos:.@[1]\n",
      "   3   3   0   0  | ADJ->ADV if Word:low@[0] & Word:as@[1] & Pos:ADP@[1]\n",
      "   3   3   0   0  | ADJ->NOUN if Word:good@[0] & Word:of@[1] & Pos:ADP@[1]\n",
      "   3   3   0   0  | ADJ->NOUN if Word:past@[0] & Word:,@[1] & Pos:.@[1]\n",
      "   3   3   0   0  | ADP->ADV if Word:as@[0] & Word:many@[1] & Pos:ADJ@[1]\n",
      "   3   3   0   0  | ADP->ADV if Word:as@[0] & Word:much@[1] & Pos:ADJ@[1]\n",
      "   3   3   0   0  | ADP->ADV if Word:before@[0] & Word:,@[1] & Pos:.@[1]\n",
      "   3   3   0   0  | ADP->ADV if Word:before@[0] & Word:.@[1] & Pos:.@[1]\n",
      "   3   3   0   0  | ADP->DET if Word:that@[0] & Word:day@[1] & Pos:NOUN@[1]\n",
      "   3   3   0   0  | ADP->DET if Word:that@[0] & Word:way@[1] & Pos:NOUN@[1]\n",
      "   3   3   0   0  | ADP->PRT if Word:in@[0] & Word:,@[1] & Pos:.@[1]\n",
      "   3   3   0   0  | ADP->PRT if Word:on@[0] & Word:in@[1] & Pos:ADP@[1]\n",
      "   3   3   0   0  | NOUN->VERB if Word:calls@[0] & Word:for@[1] & Pos:ADP@[1]\n",
      "   3   3   0   0  | VERB->NOUN if Word:left@[0] & Word:.@[1] & Pos:.@[1]\n"
     ]
    }
   ],
   "source": [
    "min_acc = None\n",
    "start = time.time()\n",
    "brill_tagger = trainer.train(train_sents, 300, 3, min_acc)\n",
    "finish = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BrillTagger время обучения =  34.00211477279663\n",
      "BrillTagger accuracy =  0.8583673876208512\n"
     ]
    }
   ],
   "source": [
    "print(\"BrillTagger время обучения = \", finish - start)\n",
    "print(\"BrillTagger accuracy = \", brill_tagger.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для обучения Brilltagger нужен какой-нибудь тэггер, я взял UnigrammTagger, и свод правил, взял стандартный brill24(). При обучении алгоритм выбирает нужные правила, которые действительно улучшают качество работы базового алгоритма. Тэггер обучен на brown корпусе, категория \"news\". Показал неплохое качество, но работает довольно долго. Думаю подбором правил и базового тэггера можно добиться хорошего качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Выделение именованных сущностей (NER)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.1. Генерация признаков для CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Выделение именованных сущностей - другая распространенная задача разметки последовательности слов. Чаще всего она решается марковскими моделями максимальной энтропии (MEMM) или условными случайными полями (CRF). При этом основная сложность заключается в генерации  хороших признаков. \n",
    "\n",
    "В данном задании Вам требуется придумать и использовать множество признаков для обучения CRF из библиотеки CRFsuite. В этой библиотеке реализована linear-chain CRF с потенциалами двух типов (аналогично HMM):\n",
    "\n",
    "$$ \\psi_{mk}(t_{i-1}, t_{i}) = [t_{i-1} = m] \\, [t_{i} = k]; \\quad \\psi_{jk}(t_{i}, x_i) = [t_{i} = k] \\, f_j(x_i)$$\n",
    "\n",
    "\n",
    "Потенциалы первого типа назвают transition features, они зависят только от биграмм меток. Потенциалы второго типа -- label-observation (node-observation) featrues; они зависят от метки и признаков наблюдаемого слова (observation features). Несмотря на то, что в формуле явно участвует текущее слово $x_i$, подход остается полностью корректным, когда признаки зависят также от контекста слова (соседних слов). Это следствие того, что CRF является дискриминативной моделью, и наблюдаемые переменные $X$ не моделируются. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Указания к заданию:** \n",
    "- Загрузите из NLTK обучающие и тестовые датасеты для задачи выделения именованных сущеностей CoNLL 2002 shared task на английском, испанском и голландском языках в BIO-нотации (nltk.corpus.conll2002).\n",
    "- Для обучения CRF модели библиотеке необходимо передать последовательность наблюдаемых признаков $f_j(x_i)$ и меток $y_i$. Ниже приведен весь технический код, который позволит сконцентрироваться только на самом творческом этапе -- генерации признаков.\n",
    "- Оцените качество приведенного решения. \n",
    "- Ваша задача заключается в том, чтобы повысить его. Помимо генерации новых признаков, можно обратить внимание на параметры обучения, в частности, feature.minfreq позволяет отсеивать редкие признаки.  \n",
    "- При проверке задания будет оцениваться как достигнутое качество, так и разнообразие/оригинальность использованных признаков. Если вы попробовали какие-то признаки, но они не помогли, также включите их в отчет. \n",
    "- Если у Вас закончилась фантазия, почитайте обзоры и статьи по теме.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reduce_mask(word) :\n",
    "    res = ''\n",
    "    for i in range(len(word)) :\n",
    "        if word[i].isdigit() :\n",
    "            res += 'd'\n",
    "        elif word[i].isalpha() :\n",
    "            if word[i].isupper() :\n",
    "                res += 'X'\n",
    "            else :\n",
    "                res += 'x'\n",
    "        else :\n",
    "            res += word[i]\n",
    "        if i > 0 and res[-2:][0] == res[-2:][1] :\n",
    "            res = res[:len(res)-1]\n",
    "    return res\n",
    "def mask(word) :\n",
    "    res = ''\n",
    "    for i in range(len(word)) :\n",
    "        if word[i].isdigit() :\n",
    "            res += 'd'\n",
    "        elif word[i].isalpha() :\n",
    "            if word[i].isupper() :\n",
    "                res += 'X'\n",
    "            else :\n",
    "                res += 'x'\n",
    "        else :\n",
    "            res += word[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's define very simple example features.\n",
    "\n",
    "def word2features(sent, i):\n",
    "\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[:3]=' + word[:3],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.islower=%s' % word.islower(),\n",
    "        'word.isalnum=%s' % word.isalnum(),\n",
    "        'word.isalpha=%s' % word.isalpha(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word_mask=' + mask(word),\n",
    "        'word_reduce_mask=' + reduce_mask(word),\n",
    "        'word_point=%s' % (word.count('.') > 0),\n",
    "        'word_hyphen=%s' % (word.count('-') > 0)\n",
    "        \n",
    "    ]\n",
    "    if i < len(sent)-1 :\n",
    "        word2 = sent[i+1][0]\n",
    "        postag2 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word2.lower(),\n",
    "            'word1[-3:]=' + word2[-3:],\n",
    "            'word1[:3]=' + word2[:3],\n",
    "            '+1:word.isupper=%s' % word2.isupper(),\n",
    "            '+1:word.islower=%s' % word2.islower(),\n",
    "            '+1:word.isalnum=%s' % word2.isalnum(),\n",
    "            '+1:word.isalpha=%s' % word2.isalpha(),\n",
    "            '+1:word.isdigit=%s' % word2.isdigit(),\n",
    "            '+1:postag=' + postag2,\n",
    "            '+1:word.istitle=%s' % word2.istitle(),\n",
    "            '0+1:word=' + word.lower() + word2.lower(),\n",
    "            'word2_mask=' + mask(word2),\n",
    "            'word2_reduce_mask=' + reduce_mask(word2),\n",
    "            '0+1:word_mask=' + mask(word) + mask(word2),\n",
    "            'word2_point=%s' % (word2.count('.') > 0),\n",
    "            'word2_hyphen=%s' % (word2.count('-') > 0)\n",
    "        ])\n",
    "        if i < len(sent) - 2 :\n",
    "            word3 = sent[i+2][0]\n",
    "            postag3 = sent[i+2][1]\n",
    "            features.extend([\n",
    "                '+2:word.isupper=%s' % word3.isupper(),\n",
    "                '+2:postag=' + postag3,\n",
    "                '+2:word.istitle=%s' % word3.istitle(),\n",
    "                'word3_mask=' + mask(word3),\n",
    "                '1+2:word_mask=' + mask(word2) + mask(word3)\n",
    "            ])\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            'word2[-3:]=' + word1[-3:],\n",
    "            'word2[:3]=' + word1[:3],\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:word.islower=%s' % word1.islower(),\n",
    "            '-1:word.isalnum=%s' % word1.isalnum(),\n",
    "            '-1:word.isalpha=%s' % word1.isalpha(),\n",
    "            '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1+0:word=' + word1.lower() + word.lower(),\n",
    "            'word1_mask=' + mask(word1),\n",
    "            'word1_reduce_mask=' + reduce_mask(word1),\n",
    "            '-1+0:word_mask=' + mask(word1) + mask(word),\n",
    "            'word1_point=%s' % (word1.count('.') > 0),\n",
    "            'word1_hyphen=%s' % (word1.count('-') > 0)\n",
    "        ])\n",
    "        if i > 1:\n",
    "            word4 = sent[i-2][0]\n",
    "            postag4 = sent[i-2][1]\n",
    "            features.extend([\n",
    "                '-2:word.isupper=%s' % word4.isupper(),\n",
    "                '-2:postag=' + postag4,\n",
    "                '-2:word.istitle=%s' % word4.istitle(),\n",
    "                'word4_mask=' + mask(word4),\n",
    "                '-2-1:word_mask=' + mask(word4) + mask(word1)\n",
    "            ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для генерации признаков текущего слова использовались : само слово и его тэг, 2 предыдущих слова с их тэгами и 2 последющих слова с их тэгами. В качестве признаков использовались суффик и префикс слова, тэг, бинарные признаки типа (слово ничинается с большой буквы, состоит из цифр и букв и тд). Так же в качестве признака использовал маску слова и сокращенную маску слова, количство специальных символов в слове такких как \".\" и \"-\". На делеких словах от текущего - через одно вперед и назад, использование всех признаков понижало качество, поэтому выбрал самые информативные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's prepare functions for more comfortable work with pycrfsuite.\n",
    "\n",
    "import pycrfsuite\n",
    "\n",
    "MODEL_NAME = 'model.crfsuite'\n",
    "\n",
    "def train(train):\n",
    "    X_train = [sent2features(s) for s in train]\n",
    "    y_train = [sent2labels(s) for s in train]\n",
    "\n",
    "    trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "    trainer.set_params({'c1': 1.0, 'c2': 1e-3, 'max_iterations': 50,\n",
    "                        'feature.possible_transitions': True})\n",
    "\n",
    "    for xseq, yseq in zip(X_train, y_train):\n",
    "        trainer.append(xseq, yseq)\n",
    "\n",
    "    trainer.train(MODEL_NAME)\n",
    "\n",
    "def evaluate(test):\n",
    "    X_test = [sent2features(s) for s in test]\n",
    "    y_test = [sent2labels(s) for s in test]\n",
    "\n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open(MODEL_NAME)\n",
    "\n",
    "    y_pred = [tagger.tag(x) for x in X_test]\n",
    "\n",
    "    true_counter, total_counter = 0.0, 0.0\n",
    "    for p, t in zip(y_pred, y_test):\n",
    "        assert len(p) == len(t)\n",
    "        total_counter += len(p)\n",
    "        true_counter += sum([str(i) == str(j) for i, j in zip(p, t)])\n",
    "    return true_counter / total_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import conll2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_sents_esp = conll2002.iob_sents('esp.train')\n",
    "test_sents_esp = conll2002.iob_sents('esp.testa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRFmodel_esp время =  117.94473791122437\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "train(train_sents_esp)\n",
    "print('CRFmodel_esp время = ', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRFmodel_esp accuracy =  0.9582601137501653\n"
     ]
    }
   ],
   "source": [
    "print('CRFmodel_esp accuracy = ', evaluate(test_sents_esp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_sents_ned = conll2002.iob_sents('ned.train')\n",
    "test_sents_ned = conll2002.iob_sents('ned.testa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRFmodel_ned время =  75.13403749465942\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "train(train_sents_ned)\n",
    "print('CRFmodel_ned время = ', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRFmodel_ned accuracy =  0.9707060790192905\n"
     ]
    }
   ],
   "source": [
    "print('CRFmodel_ned accuracy = ', evaluate(test_sents_ned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_sents_eng = conll2000.iob_sents('train.txt', tagset = 'universal')\n",
    "test_sents_eng = conll2000.iob_sents('test.txt', tagset = 'universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRFmodel_eng время =  128.03015065193176\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "train(train_sents_eng)\n",
    "print('CRFmodel_eng время = ', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRFmodel_eng accuracy =  0.9542605061527746\n"
     ]
    }
   ],
   "source": [
    "print('CRFmodel_eng accuracy = ', evaluate(test_sents_eng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.2. Stanford NER tagger\n",
    "\n",
    "Воспользуйтесь StanfordNERTagger для решения задачи NER на тех же тестовых данных, только для английского языка (обучать модель здесь не требуется). Приведите данные в соответствие нужному формату. Сравните результат с полученным выше. Настройка StanfordNERTagger производится аналогично настройке StanfordPOSTagger. В качестве готовой модели можно взять 'english.all.3class.distsim.crf.ser.gz'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.environ['CLASSPATH'] = os.path.join(\n",
    "   os.path.curdir, 'stanford-ner-2014-06-16'\n",
    ")\n",
    "os.environ['STANFORD_MODELS'] = os.path.join(\n",
    "    os.path.curdir, 'stanford-ner-2014-06-16', 'classifiers'\n",
    ")\n",
    "stanford_ner_tagger = StanfordNERTagger('english.all.3class.distsim.crf.ser.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = [el[0] for lst in test_sents_eng for el in lst]\n",
    "tags = [el[2] for lst in test_sents_eng for el in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rockwell', 'ORGANIZATION'),\n",
       " ('International', 'ORGANIZATION'),\n",
       " ('Corp.', 'ORGANIZATION'),\n",
       " (\"'s\", 'O'),\n",
       " ('Tulsa', 'LOCATION'),\n",
       " ('unit', 'O'),\n",
       " ('said', 'O'),\n",
       " ('it', 'O'),\n",
       " ('signed', 'O'),\n",
       " ('a', 'O'),\n",
       " ('tentative', 'O'),\n",
       " ('agreement', 'O'),\n",
       " ('extending', 'O'),\n",
       " ('its', 'O'),\n",
       " ('contract', 'O'),\n",
       " ('with', 'O'),\n",
       " ('Boeing', 'ORGANIZATION'),\n",
       " ('Co.', 'ORGANIZATION'),\n",
       " ('to', 'O'),\n",
       " ('provide', 'O'),\n",
       " ('structural', 'O'),\n",
       " ('parts', 'O'),\n",
       " ('for', 'O'),\n",
       " ('Boeing', 'ORGANIZATION'),\n",
       " (\"'s\", 'O'),\n",
       " ('747', 'O'),\n",
       " ('jetliners', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Rockwell', 'PERSON'),\n",
       " ('said', 'O'),\n",
       " ('the', 'O'),\n",
       " ('agreement', 'O'),\n",
       " ('calls', 'O'),\n",
       " ('for', 'O'),\n",
       " ('it', 'O'),\n",
       " ('to', 'O'),\n",
       " ('supply', 'O'),\n",
       " ('200', 'O'),\n",
       " ('additional', 'O'),\n",
       " ('so-called', 'O'),\n",
       " ('shipsets', 'O'),\n",
       " ('for', 'O'),\n",
       " ('the', 'O'),\n",
       " ('planes', 'O'),\n",
       " ('.', 'O'),\n",
       " ('These', 'O'),\n",
       " ('include', 'O'),\n",
       " (',', 'O'),\n",
       " ('among', 'O'),\n",
       " ('other', 'O'),\n",
       " ('parts', 'O'),\n",
       " (',', 'O'),\n",
       " ('each', 'O'),\n",
       " ('jetliner', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " ('two', 'O'),\n",
       " ('major', 'O'),\n",
       " ('bulkheads', 'O'),\n",
       " (',', 'O'),\n",
       " ('a', 'O'),\n",
       " ('pressure', 'O'),\n",
       " ('floor', 'O'),\n",
       " (',', 'O'),\n",
       " ('torque', 'O'),\n",
       " ('box', 'O'),\n",
       " (',', 'O'),\n",
       " ('fixed', 'O'),\n",
       " ('leading', 'O'),\n",
       " ('edges', 'O'),\n",
       " ('for', 'O'),\n",
       " ('the', 'O'),\n",
       " ('wings', 'O'),\n",
       " ('and', 'O'),\n",
       " ('an', 'O'),\n",
       " ('aft', 'O'),\n",
       " ('keel', 'O'),\n",
       " ('beam', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Under', 'O'),\n",
       " ('the', 'O'),\n",
       " ('existing', 'O'),\n",
       " ('contract', 'O'),\n",
       " (',', 'O'),\n",
       " ('Rockwell', 'ORGANIZATION'),\n",
       " ('said', 'O'),\n",
       " (',', 'O'),\n",
       " ('it', 'O'),\n",
       " ('has', 'O'),\n",
       " ('already', 'O'),\n",
       " ('delivered', 'O'),\n",
       " ('793', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('shipsets', 'O'),\n",
       " ('to', 'O'),\n",
       " ('Boeing', 'ORGANIZATION'),\n",
       " ('.', 'O'),\n",
       " ('Rockwell', 'PERSON'),\n",
       " (',', 'O'),\n",
       " ('based', 'O'),\n",
       " ('in', 'O'),\n",
       " ('El', 'LOCATION'),\n",
       " ('Segundo', 'LOCATION'),\n",
       " (',', 'O'),\n",
       " ('Calif.', 'LOCATION'),\n",
       " (',', 'O'),\n",
       " ('is', 'O'),\n",
       " ('an', 'O'),\n",
       " ('aerospace', 'O'),\n",
       " (',', 'O'),\n",
       " ('electronics', 'O'),\n",
       " (',', 'O'),\n",
       " ('automotive', 'O'),\n",
       " ('and', 'O'),\n",
       " ('graphics', 'O'),\n",
       " ('concern', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Frank', 'PERSON'),\n",
       " ('Carlucci', 'PERSON'),\n",
       " ('III', 'PERSON'),\n",
       " ('was', 'O'),\n",
       " ('named', 'O'),\n",
       " ('to', 'O'),\n",
       " ('this', 'O'),\n",
       " ('telecommunications', 'O'),\n",
       " ('company', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " ('board', 'O'),\n",
       " (',', 'O'),\n",
       " ('filling', 'O'),\n",
       " ('the', 'O'),\n",
       " ('vacancy', 'O'),\n",
       " ('created', 'O'),\n",
       " ('by', 'O'),\n",
       " ('the', 'O'),\n",
       " ('death', 'O'),\n",
       " ('of', 'O'),\n",
       " ('William', 'PERSON'),\n",
       " ('Sobey', 'PERSON'),\n",
       " ('last', 'O'),\n",
       " ('May', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Mr.', 'O'),\n",
       " ('Carlucci', 'PERSON'),\n",
       " (',', 'O'),\n",
       " ('59', 'O'),\n",
       " ('years', 'O'),\n",
       " ('old', 'O'),\n",
       " (',', 'O'),\n",
       " ('served', 'O'),\n",
       " ('as', 'O'),\n",
       " ('defense', 'ORGANIZATION'),\n",
       " ('secretary', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Reagan', 'PERSON'),\n",
       " ('administration', 'O'),\n",
       " ('.', 'O'),\n",
       " ('In', 'O'),\n",
       " ('January', 'O'),\n",
       " (',', 'O'),\n",
       " ('he', 'O'),\n",
       " ('accepted', 'O'),\n",
       " ('the', 'O'),\n",
       " ('position', 'O'),\n",
       " ('of', 'O'),\n",
       " ('vice', 'O'),\n",
       " ('chairman', 'O'),\n",
       " ('of', 'O'),\n",
       " ('Carlyle', 'ORGANIZATION'),\n",
       " ('Group', 'ORGANIZATION'),\n",
       " (',', 'O'),\n",
       " ('a', 'O'),\n",
       " ('merchant', 'O'),\n",
       " ('banking', 'O'),\n",
       " ('concern', 'O'),\n",
       " ('.', 'O'),\n",
       " ('SHEARSON', 'ORGANIZATION'),\n",
       " ('LEHMAN', 'ORGANIZATION'),\n",
       " ('HUTTON', 'ORGANIZATION'),\n",
       " ('Inc', 'ORGANIZATION'),\n",
       " ('.', 'O'),\n",
       " ('Thomas', 'PERSON'),\n",
       " ('E.', 'PERSON'),\n",
       " ('Meador', 'PERSON'),\n",
       " (',', 'O'),\n",
       " ('42', 'O'),\n",
       " ('years', 'O'),\n",
       " ('old', 'O'),\n",
       " (',', 'O'),\n",
       " ('was', 'O'),\n",
       " ('named', 'O'),\n",
       " ('president', 'O'),\n",
       " ('and', 'O'),\n",
       " ('chief', 'O'),\n",
       " ('operating', 'O'),\n",
       " ('officer', 'O'),\n",
       " ('of', 'O'),\n",
       " ('Balcor', 'ORGANIZATION'),\n",
       " ('Co.', 'ORGANIZATION'),\n",
       " (',', 'O'),\n",
       " ('a', 'O'),\n",
       " ('Skokie', 'LOCATION'),\n",
       " (',', 'O'),\n",
       " ('Ill.', 'LOCATION'),\n",
       " (',', 'O'),\n",
       " ('subsidiary', 'O'),\n",
       " ('of', 'O'),\n",
       " ('this', 'O'),\n",
       " ('New', 'LOCATION'),\n",
       " ('York', 'LOCATION'),\n",
       " ('investment', 'O'),\n",
       " ('banking', 'O'),\n",
       " ('firm', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Balcor', 'ORGANIZATION'),\n",
       " (',', 'O'),\n",
       " ('which', 'O'),\n",
       " ('has', 'O'),\n",
       " ('interests', 'O'),\n",
       " ('in', 'O'),\n",
       " ('real', 'O'),\n",
       " ('estate', 'O'),\n",
       " (',', 'O'),\n",
       " ('said', 'O'),\n",
       " ('the', 'O'),\n",
       " ('position', 'O'),\n",
       " ('is', 'O'),\n",
       " ('newly', 'O'),\n",
       " ('created', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Mr.', 'O'),\n",
       " ('Meador', 'PERSON'),\n",
       " ('had', 'O'),\n",
       " ('been', 'O'),\n",
       " ('executive', 'O'),\n",
       " ('vice', 'O'),\n",
       " ('president', 'O'),\n",
       " ('of', 'O'),\n",
       " ('Balcor', 'ORGANIZATION'),\n",
       " ('.', 'O'),\n",
       " ('In', 'O'),\n",
       " ('addition', 'O'),\n",
       " ('to', 'O'),\n",
       " ('his', 'O'),\n",
       " ('previous', 'O'),\n",
       " ('real-estate', 'O'),\n",
       " ('investment', 'O'),\n",
       " ('and', 'O'),\n",
       " ('asset-management', 'O'),\n",
       " ('duties', 'O'),\n",
       " (',', 'O'),\n",
       " ('Mr.', 'O'),\n",
       " ('Meador', 'PERSON'),\n",
       " ('takes', 'O'),\n",
       " ('responsibility', 'O'),\n",
       " ('for', 'O'),\n",
       " ('development', 'O'),\n",
       " ('and', 'O'),\n",
       " ('property', 'O'),\n",
       " ('management', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Those', 'O'),\n",
       " ('duties', 'O'),\n",
       " ('had', 'O'),\n",
       " ('been', 'O'),\n",
       " ('held', 'O'),\n",
       " ('by', 'O'),\n",
       " ('Van', 'PERSON'),\n",
       " ('Pell', 'PERSON'),\n",
       " (',', 'O'),\n",
       " ('44', 'O'),\n",
       " (',', 'O'),\n",
       " ('who', 'O'),\n",
       " ('resigned', 'O'),\n",
       " ('as', 'O'),\n",
       " ('an', 'O'),\n",
       " ('executive', 'O'),\n",
       " ('vice', 'O'),\n",
       " ('president', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Shearson', 'ORGANIZATION'),\n",
       " ('is', 'O'),\n",
       " ('about', 'O'),\n",
       " ('60%-held', 'O'),\n",
       " ('by', 'O'),\n",
       " ('American', 'ORGANIZATION'),\n",
       " ('Express', 'ORGANIZATION'),\n",
       " ('Co', 'ORGANIZATION'),\n",
       " ('.', 'O'),\n",
       " ('Great', 'ORGANIZATION'),\n",
       " ('American', 'ORGANIZATION'),\n",
       " ('Bank', 'ORGANIZATION'),\n",
       " (',', 'O'),\n",
       " ('citing', 'O'),\n",
       " ('depressed', 'O'),\n",
       " ('Arizona', 'LOCATION'),\n",
       " ('real', 'O'),\n",
       " ('estate', 'O'),\n",
       " ('prices', 'O'),\n",
       " (',', 'O'),\n",
       " ('posted', 'O'),\n",
       " ('a', 'O'),\n",
       " ('third-quarter', 'O'),\n",
       " ('loss', 'O'),\n",
       " ('of', 'O'),\n",
       " ('$', 'O'),\n",
       " ('59.4', 'O'),\n",
       " ('million', 'O'),\n",
       " (',', 'O'),\n",
       " ('or', 'O'),\n",
       " ('$', 'O'),\n",
       " ('2.48', 'O'),\n",
       " ('a', 'O'),\n",
       " ('share', 'O'),\n",
       " ('.', 'O'),\n",
       " ('A', 'O'),\n",
       " ('year', 'O'),\n",
       " ('earlier', 'O'),\n",
       " (',', 'O'),\n",
       " ('the', 'O'),\n",
       " ('savings', 'O'),\n",
       " ('bank', 'O'),\n",
       " ('had', 'O'),\n",
       " ('earnings', 'O'),\n",
       " ('of', 'O'),\n",
       " ('$', 'O'),\n",
       " ('8.1', 'O'),\n",
       " ('million', 'O'),\n",
       " (',', 'O'),\n",
       " ('or', 'O'),\n",
       " ('33', 'O'),\n",
       " ('cents', 'O'),\n",
       " ('a', 'O'),\n",
       " ('share', 'O'),\n",
       " ('.', 'O'),\n",
       " ('For', 'O'),\n",
       " ('the', 'O'),\n",
       " ('nine', 'O'),\n",
       " ('months', 'O'),\n",
       " (',', 'O'),\n",
       " ('it', 'O'),\n",
       " ('had', 'O'),\n",
       " ('a', 'O'),\n",
       " ('loss', 'O'),\n",
       " ('of', 'O'),\n",
       " ('$', 'O'),\n",
       " ('58.3', 'O'),\n",
       " ('million', 'O'),\n",
       " (',', 'O'),\n",
       " ('or', 'O'),\n",
       " ('$', 'O'),\n",
       " ('2.44', 'O'),\n",
       " ('a', 'O'),\n",
       " ('share', 'O'),\n",
       " (',', 'O'),\n",
       " ('after', 'O'),\n",
       " ('earnings', 'O'),\n",
       " ('of', 'O'),\n",
       " ('$', 'O'),\n",
       " ('29.5', 'O'),\n",
       " ('million', 'O'),\n",
       " (',', 'O'),\n",
       " ('or', 'O'),\n",
       " ('$', 'O'),\n",
       " ('1.20', 'O'),\n",
       " ('a', 'O'),\n",
       " ('share', 'O'),\n",
       " (',', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('1988', 'O'),\n",
       " ('period', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Great', 'LOCATION'),\n",
       " ('American', 'LOCATION'),\n",
       " ('said', 'O'),\n",
       " ('it', 'O'),\n",
       " ('increased', 'O'),\n",
       " ('its', 'O'),\n",
       " ('loan-loss', 'O'),\n",
       " ('reserves', 'O'),\n",
       " ('by', 'O'),\n",
       " ('$', 'O'),\n",
       " ('93', 'O'),\n",
       " ('million', 'O'),\n",
       " ('after', 'O'),\n",
       " ('reviewing', 'O'),\n",
       " ('its', 'O'),\n",
       " ('loan', 'O'),\n",
       " ('portfolio', 'O'),\n",
       " (',', 'O'),\n",
       " ('raising', 'O'),\n",
       " ('its', 'O'),\n",
       " ('total', 'O'),\n",
       " ('loan', 'O'),\n",
       " ('and', 'O'),\n",
       " ('real', 'O'),\n",
       " ('estate', 'O'),\n",
       " ('reserves', 'O'),\n",
       " ('to', 'O'),\n",
       " ('$', 'O'),\n",
       " ('217', 'O'),\n",
       " ('million', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Before', 'O'),\n",
       " ('the', 'O'),\n",
       " ('loan-loss', 'O'),\n",
       " ('addition', 'O'),\n",
       " (',', 'O'),\n",
       " ('it', 'O'),\n",
       " ('said', 'O'),\n",
       " (',', 'O'),\n",
       " ('it', 'O'),\n",
       " ('had', 'O'),\n",
       " ('operating', 'O'),\n",
       " ('profit', 'O'),\n",
       " ('of', 'O'),\n",
       " ('$', 'O'),\n",
       " ('10', 'O'),\n",
       " ('million', 'O'),\n",
       " ('for', 'O'),\n",
       " ('the', 'O'),\n",
       " ('quarter', 'O'),\n",
       " ('.', 'O'),\n",
       " ('The', 'O'),\n",
       " ('move', 'O'),\n",
       " ('followed', 'O'),\n",
       " ('a', 'O'),\n",
       " ('round', 'O'),\n",
       " ('of', 'O'),\n",
       " ('similar', 'O'),\n",
       " ('increases', 'O'),\n",
       " ('by', 'O'),\n",
       " ('other', 'O'),\n",
       " ('lenders', 'O'),\n",
       " ('against', 'O'),\n",
       " ('Arizona', 'ORGANIZATION'),\n",
       " ('real', 'O'),\n",
       " ('estate', 'O'),\n",
       " ('loans', 'O'),\n",
       " (',', 'O'),\n",
       " ('reflecting', 'O'),\n",
       " ('a', 'O'),\n",
       " ('continuing', 'O'),\n",
       " ('decline', 'O'),\n",
       " ('in', 'O'),\n",
       " ('that', 'O'),\n",
       " ('market', 'O'),\n",
       " ('.', 'O'),\n",
       " ('In', 'O'),\n",
       " ('addition', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('increased', 'O'),\n",
       " ('reserve', 'O'),\n",
       " (',', 'O'),\n",
       " ('the', 'O'),\n",
       " ('savings', 'O'),\n",
       " ('bank', 'O'),\n",
       " ('took', 'O'),\n",
       " ('a', 'O'),\n",
       " ('special', 'O'),\n",
       " ('charge', 'O'),\n",
       " ('of', 'O'),\n",
       " ('$', 'O'),\n",
       " ('5', 'O'),\n",
       " ('million', 'O'),\n",
       " ('representing', 'O'),\n",
       " ('general', 'O'),\n",
       " ('and', 'O'),\n",
       " ('administrative', 'O'),\n",
       " ('expenses', 'O'),\n",
       " ('from', 'O'),\n",
       " ('staff', 'O'),\n",
       " ('reductions', 'O'),\n",
       " ('and', 'O'),\n",
       " ('other', 'O'),\n",
       " ('matters', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('it', 'O'),\n",
       " ('posted', 'O'),\n",
       " ('a', 'O'),\n",
       " ('$', 'O'),\n",
       " ('7.6', 'O'),\n",
       " ('million', 'O'),\n",
       " ('reduction', 'O'),\n",
       " ('in', 'O'),\n",
       " ('expected', 'O'),\n",
       " ('mortgage', 'O'),\n",
       " ('servicing', 'O'),\n",
       " ('fees', 'O'),\n",
       " (',', 'O'),\n",
       " ('reflecting', 'O'),\n",
       " ('the', 'O'),\n",
       " ('fact', 'O'),\n",
       " ('that', 'O'),\n",
       " ('more', 'O'),\n",
       " ('borrowers', 'O'),\n",
       " ('are', 'O'),\n",
       " ('prepaying', 'O'),\n",
       " ('their', 'O'),\n",
       " ('mortgages', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Arbitragers', 'O'),\n",
       " ('were', 'O'),\n",
       " (\"n't\", 'O'),\n",
       " ('the', 'O'),\n",
       " ('only', 'O'),\n",
       " ('big', 'O'),\n",
       " ('losers', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('collapse', 'O'),\n",
       " ('of', 'O'),\n",
       " ('UAL', 'ORGANIZATION'),\n",
       " ('Corp.', 'ORGANIZATION'),\n",
       " ('stock', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Look', 'O'),\n",
       " ('at', 'O'),\n",
       " ('what', 'O'),\n",
       " ('happened', 'O'),\n",
       " ('to', 'O'),\n",
       " ('UAL', 'ORGANIZATION'),\n",
       " (\"'s\", 'O'),\n",
       " ('chairman', 'O'),\n",
       " (',', 'O'),\n",
       " ('Stephen', 'PERSON'),\n",
       " ('M.', 'PERSON'),\n",
       " ('Wolf', 'PERSON'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('its', 'O'),\n",
       " ('chief', 'O'),\n",
       " ('financial', 'O'),\n",
       " ('officer', 'O'),\n",
       " (',', 'O'),\n",
       " ('John', 'PERSON'),\n",
       " ('C.', 'PERSON'),\n",
       " ('Pope', 'PERSON'),\n",
       " ('.', 'O'),\n",
       " ('On', 'O'),\n",
       " ('a', 'O'),\n",
       " ('day', 'O'),\n",
       " ('some', 'O'),\n",
       " ('United', 'ORGANIZATION'),\n",
       " ('Airlines', 'ORGANIZATION'),\n",
       " ('employees', 'O'),\n",
       " ('wanted', 'O'),\n",
       " ('Mr.', 'O'),\n",
       " ('Wolf', 'PERSON'),\n",
       " ('fired', 'O'),\n",
       " ('and', 'O'),\n",
       " ('takeover', 'O'),\n",
       " ('stock', 'O'),\n",
       " ('speculators', 'O'),\n",
       " ('wanted', 'O'),\n",
       " ('his', 'O'),\n",
       " ('scalp', 'O'),\n",
       " (',', 'O'),\n",
       " ('Messrs.', 'PERSON'),\n",
       " ('Wolf', 'PERSON'),\n",
       " ('and', 'O'),\n",
       " ('Pope', 'PERSON'),\n",
       " ('saw', 'O'),\n",
       " ('their', 'O'),\n",
       " ('prospective', 'O'),\n",
       " ('personal', 'O'),\n",
       " ('fortunes', 'O'),\n",
       " ('continue', 'O'),\n",
       " ('to', 'O'),\n",
       " ('plummet', 'O'),\n",
       " ('as', 'O'),\n",
       " ('shares', 'O'),\n",
       " ('of', 'O'),\n",
       " ('UAL', 'ORGANIZATION'),\n",
       " (',', 'O'),\n",
       " ('United', 'ORGANIZATION'),\n",
       " (\"'s\", 'O'),\n",
       " ('parent', 'O'),\n",
       " ('company', 'O'),\n",
       " (',', 'O'),\n",
       " ('dived', 'O'),\n",
       " ('$', 'O'),\n",
       " ('24.875', 'O'),\n",
       " ('on', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Big', 'ORGANIZATION'),\n",
       " ('Board', 'ORGANIZATION'),\n",
       " ('to', 'O'),\n",
       " ('close', 'O'),\n",
       " ('at', 'O'),\n",
       " ('$', 'O'),\n",
       " ('198', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Including', 'O'),\n",
       " ('Monday', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " ('plunge', 'O'),\n",
       " (',', 'O'),\n",
       " ('that', 'O'),\n",
       " ('has', 'O'),\n",
       " ('given', 'O'),\n",
       " ('the', 'O'),\n",
       " ('two', 'O'),\n",
       " ('executives', 'O'),\n",
       " ('paper', 'O'),\n",
       " ('losses', 'O'),\n",
       " ('of', 'O'),\n",
       " ('$', 'O'),\n",
       " ('49.5', 'O'),\n",
       " ('million', 'O'),\n",
       " (',', 'O'),\n",
       " ('based', 'O'),\n",
       " ('on', 'O'),\n",
       " ('what', 'O'),\n",
       " ('they', 'O'),\n",
       " ('would', 'O'),\n",
       " ('have', 'O'),\n",
       " ('realized', 'O'),\n",
       " ('had', 'O'),\n",
       " ('the', 'O'),\n",
       " ('pilots', 'O'),\n",
       " ('and', 'O'),\n",
       " ('management-led', 'O'),\n",
       " ('buy-out', 'O'),\n",
       " ('of', 'O'),\n",
       " ('UAL', 'ORGANIZATION'),\n",
       " ('gone', 'O'),\n",
       " ('through', 'O'),\n",
       " ('at', 'O'),\n",
       " ('$', 'O'),\n",
       " ('300', 'O'),\n",
       " ('a', 'O'),\n",
       " ('share', 'O'),\n",
       " ('.', 'O'),\n",
       " ('When', 'O'),\n",
       " ('bank', 'O'),\n",
       " ('financing', 'O'),\n",
       " ('for', 'O'),\n",
       " ('the', 'O'),\n",
       " ('buy-out', 'O'),\n",
       " ('collapsed', 'O'),\n",
       " ('last', 'O'),\n",
       " ('week', 'O'),\n",
       " (',', 'O'),\n",
       " ('so', 'O'),\n",
       " ('did', 'O'),\n",
       " ('UAL', 'ORGANIZATION'),\n",
       " (\"'s\", 'O'),\n",
       " ('stock', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Even', 'O'),\n",
       " ('if', 'O'),\n",
       " ('the', 'O'),\n",
       " ('banks', 'O'),\n",
       " ('resurrect', 'O'),\n",
       " ('a', 'O'),\n",
       " ('financing', 'O'),\n",
       " ('package', 'O'),\n",
       " ('at', 'O'),\n",
       " ('$', 'O'),\n",
       " ('250', 'O'),\n",
       " ('a', 'O'),\n",
       " ('share', 'O'),\n",
       " (',', 'O'),\n",
       " ('the', 'O'),\n",
       " ('two', 'O'),\n",
       " ('executives', 'O'),\n",
       " ('would', 'O'),\n",
       " ('still', 'O'),\n",
       " ('get', 'O'),\n",
       " ('about', 'O'),\n",
       " ('$', 'O'),\n",
       " ('25', 'O'),\n",
       " ('million', 'O'),\n",
       " ('less', 'O'),\n",
       " ('than', 'O'),\n",
       " ('they', 'O'),\n",
       " ('stood', 'O'),\n",
       " ('to', 'O'),\n",
       " ('gain', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('initial', 'O'),\n",
       " ('transaction', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Mr.', 'O'),\n",
       " ('Wolf', 'PERSON'),\n",
       " ('owns', 'O'),\n",
       " ('75,000', 'O'),\n",
       " ('UAL', 'ORGANIZATION'),\n",
       " ('shares', 'O'),\n",
       " ('and', 'O'),\n",
       " ('has', 'O'),\n",
       " ('options', 'O'),\n",
       " ('to', 'O'),\n",
       " ('buy', 'O'),\n",
       " ('another', 'O'),\n",
       " ('250,000', 'O'),\n",
       " ('at', 'O'),\n",
       " ('$', 'O'),\n",
       " ('83.3125', 'O'),\n",
       " ('each', 'O'),\n",
       " ('.', 'O'),\n",
       " ('In', 'O'),\n",
       " ('the', 'O'),\n",
       " ('$', 'O'),\n",
       " ('300-a-share', 'O'),\n",
       " ('buyout', 'O'),\n",
       " (',', 'O'),\n",
       " ('that', 'O'),\n",
       " ('totaled', 'O'),\n",
       " ('about', 'O'),\n",
       " ('$', 'O'),\n",
       " ('76.7', 'O'),\n",
       " ('million', 'O'),\n",
       " ('.', 'O'),\n",
       " ('By', 'O'),\n",
       " ('yesterday', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " ('close', 'O'),\n",
       " ('of', 'O'),\n",
       " ('trading', 'O'),\n",
       " (',', 'O'),\n",
       " ('it', 'O'),\n",
       " ('was', 'O'),\n",
       " ('good', 'O'),\n",
       " ('for', 'O'),\n",
       " ('a', 'O'),\n",
       " ('paltry', 'O'),\n",
       " ('$', 'O'),\n",
       " ('43.5', 'O'),\n",
       " ('million', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Of', 'O'),\n",
       " ('course', 'O'),\n",
       " (',', 'O'),\n",
       " ('Mr.', 'O'),\n",
       " ('Wolf', 'PERSON'),\n",
       " (',', 'O'),\n",
       " ('48', 'O'),\n",
       " ('years', 'O'),\n",
       " ('old', 'O'),\n",
       " (',', 'O'),\n",
       " ('has', 'O'),\n",
       " ('some', 'O'),\n",
       " ('savings', 'O'),\n",
       " ('.', 'O'),\n",
       " ('He', 'O'),\n",
       " ('left', 'O'),\n",
       " ('his', 'O'),\n",
       " ('last', 'O'),\n",
       " ('two', 'O'),\n",
       " ('jobs', 'O'),\n",
       " ('at', 'O'),\n",
       " ('Republic', 'ORGANIZATION'),\n",
       " ('Airlines', 'ORGANIZATION'),\n",
       " ('and', 'O'),\n",
       " ('Flying', 'O'),\n",
       " ('Tiger', 'O'),\n",
       " ('with', 'O'),\n",
       " ('combined', 'O'),\n",
       " ('stock-option', 'O'),\n",
       " ('gains', 'O'),\n",
       " ('of', 'O'),\n",
       " ('about', 'O'),\n",
       " ('$', 'O'),\n",
       " ('22', 'O'),\n",
       " ('million', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('UAL', 'ORGANIZATION'),\n",
       " ('gave', 'O'),\n",
       " ('him', 'O'),\n",
       " ('a', 'O'),\n",
       " ('$', 'O'),\n",
       " ('15', 'O'),\n",
       " ('million', 'O'),\n",
       " ('bonus', 'O'),\n",
       " ('when', 'O'),\n",
       " ('it', 'O'),\n",
       " ('hired', 'O'),\n",
       " ('him', 'O'),\n",
       " ('.', 'O'),\n",
       " ('His', 'O'),\n",
       " ('1988', 'O'),\n",
       " ('salary', 'O'),\n",
       " ('was', 'O'),\n",
       " ('$', 'O'),\n",
       " ('575,000', 'O'),\n",
       " (',', 'O'),\n",
       " ('with', 'O'),\n",
       " ('a', 'O'),\n",
       " ('$', 'O'),\n",
       " ('575,000', 'O'),\n",
       " ('bonus', 'O'),\n",
       " ('.', 'O'),\n",
       " ('The', 'O'),\n",
       " ('40-year', 'O'),\n",
       " ('old', 'O'),\n",
       " ('Mr.', 'O'),\n",
       " ('Pope', 'PERSON'),\n",
       " ('has', 'O'),\n",
       " (\"n't\", 'O'),\n",
       " ('changed', 'O'),\n",
       " ('jobs', 'O'),\n",
       " ('enough', 'O'),\n",
       " ('--', 'O'),\n",
       " ('at', 'O'),\n",
       " ('least', 'O'),\n",
       " ('the', 'O'),\n",
       " ('right', 'O'),\n",
       " ('ones', 'O'),\n",
       " ('--', 'O'),\n",
       " ('to', 'O'),\n",
       " ('stash', 'O'),\n",
       " ('away', 'O'),\n",
       " ('that', 'O'),\n",
       " ('kind', 'O'),\n",
       " ('of', 'O'),\n",
       " ('money', 'O'),\n",
       " ('.', 'O'),\n",
       " ('United', 'ORGANIZATION'),\n",
       " ('paid', 'O'),\n",
       " ('him', 'O'),\n",
       " ('a', 'O'),\n",
       " ('$', 'O'),\n",
       " ('375,000', 'O'),\n",
       " ('bonus', 'O'),\n",
       " ('to', 'O'),\n",
       " ('lure', 'O'),\n",
       " ('him', 'O'),\n",
       " ('away', 'O'),\n",
       " ('from', 'O'),\n",
       " ('American', 'ORGANIZATION'),\n",
       " ('Airlines', 'ORGANIZATION'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('he', 'O'),\n",
       " ('was', 'O'),\n",
       " ('paid', 'O'),\n",
       " ('a', 'O'),\n",
       " ('salary', 'O'),\n",
       " ('of', 'O'),\n",
       " ('$', 'O'),\n",
       " ('342,122', 'O'),\n",
       " ('last', 'O'),\n",
       " ('year', 'O'),\n",
       " ('with', 'O'),\n",
       " ('a', 'O'),\n",
       " ('$', 'O'),\n",
       " ('280,000', 'O'),\n",
       " ('bonus', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Mr.', 'O'),\n",
       " ('Pope', 'PERSON'),\n",
       " ('owns', 'O'),\n",
       " ('10,000', 'O'),\n",
       " ('UAL', 'ORGANIZATION'),\n",
       " ('shares', 'O'),\n",
       " ('and', 'O'),\n",
       " ('has', 'O'),\n",
       " ('options', 'O'),\n",
       " ('to', 'O'),\n",
       " ('buy', 'O'),\n",
       " ('another', 'O'),\n",
       " ('150,000', 'O'),\n",
       " ('at', 'O'),\n",
       " ('$', 'O'),\n",
       " ('69', 'O'),\n",
       " ('each', 'O'),\n",
       " ('.', 'O'),\n",
       " ('That', 'O'),\n",
       " ('came', 'O'),\n",
       " ('to', 'O'),\n",
       " ('a', 'O'),\n",
       " ('combined', 'O'),\n",
       " ('$', 'O'),\n",
       " ('37.7', 'O'),\n",
       " ('million', 'O'),\n",
       " ('under', 'O'),\n",
       " ('the', 'O'),\n",
       " ('$', 'O'),\n",
       " ('300-a-share', 'O'),\n",
       " ('buy-out', 'O'),\n",
       " (',', 'O'),\n",
       " ('but', 'O'),\n",
       " ('just', 'O'),\n",
       " ('$', 'O'),\n",
       " ('21.3', 'O'),\n",
       " ('million', 'O'),\n",
       " ('at', 'O'),\n",
       " ('yesterday', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " ('close', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('combined', 'O'),\n",
       " ('$', 'O'),\n",
       " ('114.4', 'O'),\n",
       " ('million', 'O'),\n",
       " ('the', 'O'),\n",
       " ('two', 'O'),\n",
       " ('men', 'O'),\n",
       " ('were', 'O'),\n",
       " ('scheduled', 'O'),\n",
       " ('to', 'O'),\n",
       " ('reap', 'O'),\n",
       " ('under', 'O'),\n",
       " ('the', 'O'),\n",
       " ('buy-out', 'O'),\n",
       " (',', 'O'),\n",
       " ('they', 'O'),\n",
       " ('agreed', 'O'),\n",
       " ('to', 'O'),\n",
       " ('invest', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('buy-out', 'O'),\n",
       " ('just', 'O'),\n",
       " ('$', 'O'),\n",
       " ('15', 'O'),\n",
       " ('million', 'O'),\n",
       " (',', 'O'),\n",
       " ('angering', 'O'),\n",
       " ('many', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('thousands', 'O'),\n",
       " ('of', 'O'),\n",
       " ('workers', 'O'),\n",
       " ('asked', 'O'),\n",
       " ('to', 'O'),\n",
       " ('make', 'O'),\n",
       " ('pay', 'O'),\n",
       " ('concessions', 'O'),\n",
       " ('so', 'O'),\n",
       " ('the', 'O'),\n",
       " ('buy-out', 'O'),\n",
       " ('would', 'O'),\n",
       " ('be', 'O'),\n",
       " ('a', 'O'),\n",
       " ('success', 'O'),\n",
       " ('.', 'O'),\n",
       " ('United', 'ORGANIZATION'),\n",
       " (\"'s\", 'O'),\n",
       " ('directors', 'O'),\n",
       " ('voted', 'O'),\n",
       " ('themselves', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('their', 'O'),\n",
       " ('spouses', 'O'),\n",
       " (',', 'O'),\n",
       " ('lifetime', 'O'),\n",
       " ('access', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Friendly', 'O'),\n",
       " ('Skies', 'O'),\n",
       " ('--', 'O'),\n",
       " ('free', 'O'),\n",
       " ('first-class', 'O'),\n",
       " ('travel', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('$', 'O'),\n",
       " ('20,000', 'O'),\n",
       " ('a', 'O'),\n",
       " ('year', 'O'),\n",
       " ('for', 'O'),\n",
       " ('life', 'O'),\n",
       " ('as', 'O'),\n",
       " ('well', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Conceivably', 'O'),\n",
       " (',', 'O'),\n",
       " ('in', 'O'),\n",
       " ('a', 'O'),\n",
       " ('scaled-back', 'O'),\n",
       " ('buy-out', 'O'),\n",
       " (',', 'O'),\n",
       " ('they', 'O'),\n",
       " ('could', 'O'),\n",
       " ('be', 'O'),\n",
       " ('bumped', 'O'),\n",
       " ('back', 'O'),\n",
       " ('to', 'O'),\n",
       " ('coach', 'O'),\n",
       " ('seats', 'O'),\n",
       " ('for', 'O'),\n",
       " ('life', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Thomas', 'PERSON'),\n",
       " ('H.', 'PERSON'),\n",
       " ('Johnson', 'PERSON'),\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanford_ner_tagger.tag(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Английский датасет с \"нормальными\" тэгами не нашел, поэтому просто запустил тэгер без проверки качества. Визуально работает хорошо)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
